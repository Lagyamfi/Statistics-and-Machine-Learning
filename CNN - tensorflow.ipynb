{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with MNIST dataset\n",
    "\n",
    "ref: deep learning with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for MNIST will be downloaded from Yann LeCunn's Webiste, using a helper function.\n",
    "The downloaded is stored so we dont have to redownload it anytime we run the script.\n",
    "The raw downloaded data is stored as a raw string of bytes so we use np.frombuffer to convert it into a numpy array.\n",
    "The data is further rescaled from 0 to 255 , to be between -0.5 and 0.5 to make it easy for the gradient descent algorithm.\n",
    "\n",
    "The data is extracted and returned as \\[tensor, height, width, channels\\]\n",
    "\n",
    "5000 of the images will be subset for validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:54:46.749838Z",
     "start_time": "2019-07-21T18:54:45.182827Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os, sys, time, numpy\n",
    "\n",
    "from six.moves import urllib, xrange\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:54:47.365744Z",
     "start_time": "2019-07-21T18:54:47.358121Z"
    }
   },
   "outputs": [],
   "source": [
    "#Global variables\n",
    "\n",
    "SOURCE_URL = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "WORK_DIR = \"data\"\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000\n",
    "SEED = 66478\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100 # number of steps between evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:54:48.628356Z",
     "start_time": "2019-07-21T18:54:48.598812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def download(filename):\n",
    "    # Function for downloading dataset and performing housecleaning before\n",
    "    # if required\n",
    "    if not os.path.exists(WORK_DIR):\n",
    "        os.makedirs(WORK_DIR)\n",
    "    filepath = os.path.join(WORK_DIR, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename,\n",
    "                                                filepath)\n",
    "        size = os.stat(filepath).st_size\n",
    "        print(\"Successfully downloaded\", filename, size, 'bytes.')\n",
    "    return filepath\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"\n",
    "    Extract the images into a 4D tensor [image index, y, x, channels]\n",
    "    \n",
    "    values are rescaled from [0, 255] down to [-0.5, 0.5]\n",
    "    \"\"\"\n",
    "    print(\"Extracting %s\" %filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        #remove header\n",
    "        bytestream.read(16)\n",
    "        # Read bytes for labels\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data  = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        # Center data to have mean zero and unit range\n",
    "        data = (data - (255/2.0))/255\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "        return data\n",
    "    \n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs\"\"\"\n",
    "    print(\"Extracting %s\" %filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # remove header\n",
    "        bytestream.read(8)\n",
    "        # Read bytes for lalels\n",
    "        buf = bytestream.read(num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(\n",
    "        numpy.int64)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"\n",
    "    Return  the error rate based on dense predictions and sparse labels\n",
    "    \"\"\"\n",
    "    return 100.0 - (100.0 * \n",
    "                   numpy.sum(numpy.argmax(predictions, 1) == labels) / \n",
    "                   predictions.shape[0])\n",
    "\n",
    "def model(data, train=False):\n",
    "    \"\"\" Model Definition\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding so that output feature map\n",
    "    # ha the same size as the input. Strides has the same array dimensions\n",
    "    # as the input [image index, y, x, depth]\n",
    "    \n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "    # Bias and rectified linear non-linearity\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    # Max pooling. The kernel size spec(ksize) also follows the layout of the \n",
    "    # data. We use a pooling window of 2, and a stride of 2\n",
    "    \n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                         ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1],\n",
    "                         padding='SAME')\n",
    "    \n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                         ksize=[1,2,2,1],\n",
    "                         strides=[1,2,2,1],\n",
    "                         padding='SAME')\n",
    "    #Reshape the feature map cuboid into a 2D matrix to feed to the fully connected\n",
    "    # layers\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(pool,\n",
    "                        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "    # Fully connected layer. Note that '+' operation automatically broadcasts\n",
    "    # the biases\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    # Add a 50% dropout during training only. Dropout also scales activations\n",
    "    # such that no rescaling is needed at evaluation time\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "\n",
    "# utility function to evaluate a dataset by feeding batches of data to \n",
    "# {eval_data} and pulling the results from {eval_predictions}.\n",
    "# saves memory and enables running on GPUs\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"\n",
    "    Get predictions for a dataset by running it in small batches.\n",
    "    \"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\"\n",
    "                        % size)\n",
    "    predictions = numpy.ndarray(shape=(size, NUM_LABELS),\n",
    "                               dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[begin:end,:] = sess.run(eval_prediction,\n",
    "                                                feed_dict={eval_data : data[begin:end, ...]})\n",
    "        else:\n",
    "            batch_predictions = sess.run(eval_prediction,\n",
    "                                         feed_dict={eval_data: data[-EVAL_BATCH_SIZE:,...]})\n",
    "            predictions[begin:,:] = batch_predictions[begin - size:, :]\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture for the CNN will use 2 convolutional layers interspersed with 2 pooling layers and then end with two fully connected layers.\n",
    "\n",
    "We create weights only for the convolutional and fully connected layers and not for the pooling layers as they dont learn any weights.\n",
    "\n",
    "Separate tensors are created to hold the weights for each of the relevant layers. Values are also created for the biases, both for the convolution and fully connected layers.\n",
    "\n",
    "The input images are of size=28. During the each of the pooling stages, the current input size is reduced by 2. So the shape of the first fully connected layer is created accordingly.\n",
    "The first fully connected layer converts the output of the convolutional layer to a vector of length 512.\n",
    "\n",
    "\n",
    "The shape of the second fully connected label is created knowing we want a 10-way classification ouput. (512,10).\n",
    "\n",
    "when defining the architecture, a dropout layer is added after the final fully connected(FCN) layer, and a check if performed to ensure this included only for the training and not for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:54:49.798061Z",
     "start_time": "2019-07-21T18:54:49.262329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "train_data_filename = download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract data into numpy arrats\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "# Generate a validation set\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create placeholders for inputting the training images and corresponding labels.\n",
    "\n",
    "A separate placeholder is created also for the evaluation, to allow to input larger batches during the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:55:26.370727Z",
     "start_time": "2019-07-21T18:55:26.303492Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step using the {feed_dict} argument to the Run() call\n",
    "\n",
    "train_data_node = tf.placeholder(tf.float32,\n",
    "                                shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(tf.float32, \n",
    "                           shape=(EVAL_BATCH_SIZE,IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "# The variables below hold all the trainable weights. They are passed an initial\n",
    "# value which will be assigned when we call  run on the initializer method\n",
    "\n",
    "# 5x5 filter, depth 32\n",
    "conv1_weights = tf.Variable(tf.truncated_normal([5,5,NUM_CHANNELS,32],\n",
    "                                                stddev=0.1,\n",
    "                                                seed=SEED, dtype=tf.float32))\n",
    "conv1_biases = tf.Variable(tf.zeros([32], dtype=tf.float32))\n",
    "conv2_weights = tf.Variable(tf.truncated_normal([5,5,32,64], \n",
    "                                                stddev=0.1,\n",
    "                                                seed=SEED, \n",
    "                                                dtype=tf.float32))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64],\n",
    "                                       dtype=tf.float32))\n",
    "# fully connected, depth 512\n",
    "fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "                         stddev=0.1,\n",
    "                         seed=SEED,\n",
    "                         dtype=tf.float32))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=tf.float32))\n",
    "fc2_weights = tf.Variable(tf.truncated_normal([512, NUM_LABELS],\n",
    "                                              stddev=0.1,\n",
    "                                              seed=SEED,\n",
    "                                              dtype=tf.float32))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:55:27.262878Z",
     "start_time": "2019-07-21T18:55:26.968151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training computation: logits + cross-entropy loss\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=train_labels_node,\n",
    "                                                                    logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) \n",
    "               + tf.nn.l2_loss(fc1_biases)\n",
    "               + tf.nn.l2_loss(fc2_weights)\n",
    "               + tf.nn.l2_loss(fc2_biases))\n",
    "\n",
    "# Add the regularization term to the loss\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# optimizer: set up a variable that's incrememted once per batch and controls\n",
    "# the learning rate decay\n",
    "batch = tf.Variable(0, dtype=tf.float32)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01\n",
    "learning_rate = tf.train.exponential_decay(0.01, \n",
    "                                           batch * BATCH_SIZE,\n",
    "                                           train_size,\n",
    "                                          0.95,\n",
    "                                          staircase=True)\n",
    "\n",
    "# use simple momentum for the optimization\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                    global_step=batch)\n",
    "\n",
    "# Predictions for the current training minibatch\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# predictions for the test and validation, which we will compute less often\n",
    "eval_prediction = tf.nn.softmax(model(eval_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training we start by defining a session and initializing the variables. We then proceed with the training in batches of the input, calculating the offset and incrementing as we train.\n",
    "We subset the data and corresponding to be supplied for the current training using the offset and the batch size. \n",
    "\n",
    "A dictionary is created to hold these data as a feed_dict and supplied to the optimizer. This is the process of minibatching.\n",
    "\n",
    "An evaluation is done at each of the evaluation frequency defined earlier. The evaluation is done on the mini batches as our network is crafted this way.\n",
    "\n",
    "Note that the learning rate is reduced exponentially as the training progresses.\n",
    "\n",
    "We add a little instrumentation to track the performance of our model as we train based on the validation set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T20:15:51.841212Z",
     "start_time": "2019-07-21T18:55:54.721052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 0.00), 4.9 ms\n",
      "Minibatch loss: 8.334, learning rate: 0.010000\n",
      "Minibatch error: 85.9%\n",
      "Validation error: 84.6%\n",
      "Test error: 84.0%\n",
      "Test error: 75.1%\n",
      "Test error: 78.4%\n",
      "Test error: 69.1%\n",
      "Test error: 66.0%\n",
      "Test error: 66.0%\n",
      "Test error: 67.8%\n",
      "Test error: 64.4%\n",
      "Test error: 55.9%\n",
      "Test error: 58.4%\n",
      "Test error: 55.2%\n",
      "Test error: 51.1%\n",
      "Test error: 48.0%\n",
      "Test error: 44.6%\n",
      "Test error: 41.4%\n",
      "Test error: 38.1%\n",
      "Test error: 35.7%\n",
      "Test error: 32.7%\n",
      "Test error: 30.3%\n",
      "Test error: 27.8%\n",
      "Test error: 25.6%\n",
      "Test error: 24.4%\n",
      "Test error: 24.4%\n",
      "Test error: 24.2%\n",
      "Test error: 23.7%\n",
      "Test error: 22.7%\n",
      "Test error: 22.3%\n",
      "Test error: 20.6%\n",
      "Test error: 18.8%\n",
      "Test error: 18.1%\n",
      "Test error: 17.2%\n",
      "Test error: 16.1%\n",
      "Test error: 15.7%\n",
      "Test error: 15.7%\n",
      "Test error: 15.7%\n",
      "Test error: 15.5%\n",
      "Test error: 14.6%\n",
      "Test error: 13.7%\n",
      "Test error: 13.7%\n",
      "Test error: 14.3%\n",
      "Test error: 15.2%\n",
      "Test error: 15.2%\n",
      "Test error: 14.0%\n",
      "Test error: 12.4%\n",
      "Test error: 11.8%\n",
      "Test error: 11.6%\n",
      "Test error: 12.2%\n",
      "Test error: 12.6%\n",
      "Test error: 12.3%\n",
      "Test error: 11.4%\n",
      "Test error: 10.6%\n",
      "Test error: 10.2%\n",
      "Test error: 10.0%\n",
      "Test error: 10.7%\n",
      "Test error: 11.0%\n",
      "Test error: 11.6%\n",
      "Test error: 10.6%\n",
      "Test error: 9.8%\n",
      "Test error: 9.3%\n",
      "Test error: 9.3%\n",
      "Test error: 9.5%\n",
      "Test error: 10.4%\n",
      "Test error: 11.3%\n",
      "Test error: 11.8%\n",
      "Test error: 12.2%\n",
      "Test error: 12.4%\n",
      "Test error: 11.6%\n",
      "Test error: 10.4%\n",
      "Test error: 9.5%\n",
      "Test error: 8.8%\n",
      "Test error: 8.7%\n",
      "Test error: 8.4%\n",
      "Test error: 8.5%\n",
      "Test error: 8.8%\n",
      "Test error: 9.0%\n",
      "Test error: 9.7%\n",
      "Test error: 10.4%\n",
      "Test error: 10.8%\n",
      "Test error: 10.6%\n",
      "Test error: 10.2%\n",
      "Test error: 9.5%\n",
      "Test error: 8.3%\n",
      "Test error: 8.2%\n",
      "Test error: 9.2%\n",
      "Test error: 10.3%\n",
      "Test error: 11.2%\n",
      "Test error: 11.4%\n",
      "Test error: 11.0%\n",
      "Test error: 10.8%\n",
      "Test error: 10.3%\n",
      "Test error: 9.5%\n",
      "Test error: 8.9%\n",
      "Test error: 8.3%\n",
      "Test error: 7.8%\n",
      "Test error: 7.5%\n",
      "Test error: 7.4%\n",
      "Test error: 7.4%\n",
      "Test error: 7.8%\n",
      "Test error: 8.1%\n",
      "Test error: 8.2%\n",
      "Step 100 (epoch 0.12), 3289.1 ms\n",
      "Minibatch loss: 3.256, learning rate: 0.010000\n",
      "Minibatch error: 7.8%\n",
      "Validation error: 7.6%\n",
      "Test error: 8.2%\n",
      "Test error: 7.9%\n",
      "Test error: 7.4%\n",
      "Test error: 7.0%\n",
      "Test error: 6.7%\n",
      "Test error: 6.8%\n",
      "Test error: 7.0%\n",
      "Test error: 6.9%\n",
      "Test error: 6.9%\n",
      "Test error: 6.8%\n",
      "Test error: 7.1%\n",
      "Test error: 7.1%\n",
      "Test error: 7.5%\n",
      "Test error: 7.4%\n",
      "Test error: 7.3%\n",
      "Test error: 6.9%\n",
      "Test error: 6.3%\n",
      "Test error: 6.1%\n",
      "Test error: 6.2%\n",
      "Test error: 6.8%\n",
      "Test error: 7.5%\n",
      "Test error: 8.3%\n",
      "Test error: 8.7%\n",
      "Test error: 8.4%\n",
      "Test error: 7.4%\n",
      "Test error: 6.8%\n",
      "Test error: 6.3%\n",
      "Test error: 6.2%\n",
      "Test error: 6.2%\n",
      "Test error: 6.5%\n",
      "Test error: 6.6%\n",
      "Test error: 7.0%\n",
      "Test error: 7.3%\n",
      "Test error: 7.4%\n",
      "Test error: 7.4%\n",
      "Test error: 7.3%\n",
      "Test error: 7.0%\n",
      "Test error: 6.6%\n",
      "Test error: 6.2%\n",
      "Test error: 5.8%\n",
      "Test error: 5.5%\n",
      "Test error: 5.4%\n",
      "Test error: 5.2%\n",
      "Test error: 5.2%\n",
      "Test error: 5.2%\n",
      "Test error: 5.0%\n",
      "Test error: 5.0%\n",
      "Test error: 4.8%\n",
      "Test error: 4.9%\n",
      "Test error: 4.8%\n",
      "Test error: 4.7%\n",
      "Test error: 4.7%\n",
      "Test error: 4.7%\n",
      "Test error: 4.8%\n",
      "Test error: 4.8%\n",
      "Test error: 4.6%\n",
      "Test error: 4.5%\n",
      "Test error: 4.3%\n",
      "Test error: 4.2%\n",
      "Test error: 4.4%\n",
      "Test error: 4.4%\n",
      "Test error: 4.5%\n",
      "Test error: 4.5%\n",
      "Test error: 4.6%\n",
      "Test error: 4.6%\n",
      "Test error: 4.5%\n",
      "Test error: 4.5%\n",
      "Test error: 4.6%\n",
      "Test error: 4.5%\n",
      "Test error: 4.4%\n",
      "Test error: 4.4%\n",
      "Test error: 4.4%\n",
      "Test error: 4.5%\n",
      "Test error: 4.8%\n",
      "Test error: 5.0%\n",
      "Test error: 5.2%\n",
      "Test error: 5.0%\n",
      "Test error: 4.8%\n",
      "Test error: 4.7%\n",
      "Test error: 4.5%\n",
      "Test error: 4.4%\n",
      "Test error: 4.4%\n",
      "Test error: 4.3%\n",
      "Test error: 4.3%\n",
      "Test error: 4.0%\n",
      "Test error: 3.8%\n",
      "Test error: 3.6%\n",
      "Test error: 3.7%\n",
      "Test error: 3.8%\n",
      "Test error: 3.9%\n",
      "Test error: 4.1%\n",
      "Test error: 4.3%\n",
      "Test error: 4.5%\n",
      "Test error: 4.5%\n",
      "Test error: 4.7%\n",
      "Test error: 4.7%\n",
      "Test error: 4.8%\n",
      "Test error: 4.7%\n",
      "Test error: 4.6%\n",
      "Test error: 4.6%\n",
      "Step 200 (epoch 0.23), 3411.0 ms\n",
      "Minibatch loss: 3.359, learning rate: 0.010000\n",
      "Minibatch error: 10.9%\n",
      "Validation error: 4.4%\n",
      "Test error: 4.6%\n",
      "Test error: 4.6%\n",
      "Test error: 4.6%\n",
      "Test error: 4.2%\n",
      "Test error: 4.1%\n",
      "Test error: 3.9%\n",
      "Test error: 3.7%\n",
      "Test error: 3.5%\n",
      "Test error: 3.4%\n",
      "Test error: 3.3%\n",
      "Test error: 3.3%\n",
      "Test error: 3.4%\n",
      "Test error: 3.8%\n",
      "Test error: 3.9%\n",
      "Test error: 4.0%\n",
      "Test error: 4.1%\n",
      "Test error: 4.1%\n",
      "Test error: 4.0%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.7%\n",
      "Test error: 3.7%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.7%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.7%\n",
      "Test error: 3.4%\n",
      "Test error: 3.4%\n",
      "Test error: 3.3%\n",
      "Test error: 3.4%\n",
      "Test error: 3.4%\n",
      "Test error: 3.6%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.9%\n",
      "Test error: 3.9%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.9%\n",
      "Test error: 4.0%\n",
      "Test error: 4.1%\n",
      "Test error: 4.0%\n",
      "Test error: 4.0%\n",
      "Test error: 3.9%\n",
      "Test error: 3.7%\n",
      "Test error: 3.6%\n",
      "Test error: 3.5%\n",
      "Test error: 3.4%\n",
      "Test error: 3.3%\n",
      "Test error: 3.2%\n",
      "Test error: 3.2%\n",
      "Test error: 3.2%\n",
      "Test error: 3.5%\n",
      "Test error: 3.6%\n",
      "Test error: 3.7%\n",
      "Test error: 3.6%\n",
      "Test error: 3.6%\n",
      "Test error: 3.4%\n",
      "Test error: 3.3%\n",
      "Test error: 3.2%\n",
      "Test error: 3.1%\n",
      "Test error: 3.2%\n",
      "Test error: 3.3%\n",
      "Test error: 3.4%\n",
      "Test error: 3.5%\n",
      "Test error: 3.7%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.9%\n",
      "Test error: 4.0%\n",
      "Test error: 3.8%\n",
      "Test error: 3.8%\n",
      "Test error: 3.7%\n",
      "Test error: 3.6%\n",
      "Test error: 3.6%\n",
      "Test error: 3.5%\n",
      "Test error: 3.3%\n",
      "Test error: 3.2%\n",
      "Test error: 3.0%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Step 300 (epoch 0.35), 3360.2 ms\n",
      "Minibatch loss: 3.143, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.9%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.9%\n",
      "Test error: 2.9%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.1%\n",
      "Test error: 3.0%\n",
      "Test error: 3.1%\n",
      "Test error: 3.1%\n",
      "Test error: 3.1%\n",
      "Test error: 3.0%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.1%\n",
      "Test error: 3.2%\n",
      "Test error: 3.2%\n",
      "Test error: 3.3%\n",
      "Test error: 3.3%\n",
      "Test error: 3.3%\n",
      "Test error: 3.2%\n",
      "Test error: 3.2%\n",
      "Test error: 3.1%\n",
      "Test error: 3.0%\n",
      "Test error: 2.9%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Step 400 (epoch 0.47), 3508.4 ms\n",
      "Minibatch loss: 3.221, learning rate: 0.010000\n",
      "Minibatch error: 7.8%\n",
      "Validation error: 2.7%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.6%\n",
      "Test error: 2.8%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 3.0%\n",
      "Test error: 2.9%\n",
      "Test error: 2.9%\n",
      "Test error: 2.9%\n",
      "Test error: 3.0%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Step 500 (epoch 0.58), 3496.3 ms\n",
      "Minibatch loss: 3.191, learning rate: 0.010000\n",
      "Minibatch error: 6.2%\n",
      "Validation error: 2.7%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.6%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.8%\n",
      "Test error: 2.9%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.7%\n",
      "Test error: 2.8%\n",
      "Test error: 2.7%\n",
      "Test error: 2.7%\n",
      "Test error: 2.6%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Step 600 (epoch 0.70), 3487.6 ms\n",
      "Minibatch loss: 3.141, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 2.0%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.4%\n",
      "Test error: 2.5%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.3%\n",
      "Test error: 2.4%\n",
      "Test error: 2.3%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Step 700 (epoch 0.81), 3518.9 ms\n",
      "Minibatch loss: 3.009, learning rate: 0.010000\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Step 800 (epoch 0.93), 3366.0 ms\n",
      "Minibatch loss: 3.034, learning rate: 0.010000\n",
      "Minibatch error: 4.7%\n",
      "Validation error: 2.0%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Step 900 (epoch 1.05), 3408.8 ms\n",
      "Minibatch loss: 2.908, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.1%\n",
      "Test error: 2.2%\n",
      "Test error: 2.1%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 1.9%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 2.0%\n",
      "Test error: 1.9%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Step 1000 (epoch 1.16), 3398.5 ms\n",
      "Minibatch loss: 2.878, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Step 1100 (epoch 1.28), 3408.9 ms\n",
      "Minibatch loss: 2.818, learning rate: 0.009500\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.8%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Step 1200 (epoch 1.40), 3500.9 ms\n",
      "Minibatch loss: 2.917, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.7%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.6%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Step 1300 (epoch 1.51), 3353.2 ms\n",
      "Minibatch loss: 2.795, learning rate: 0.009500\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 1.9%\n",
      "Test error: 1.7%\n",
      "Test error: 1.7%\n",
      "Test error: 1.6%\n",
      "Test error: 1.6%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.5%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.3%\n",
      "Test error: 1.3%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Test error: 1.4%\n",
      "Step 1400 (epoch 1.63), 3276.1 ms\n",
      "Minibatch loss: 2.847, learning rate: 0.009500\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n",
      "Test error: 1.5%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-776a28f21045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#Finally print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_in_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test error: %.1f%%'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mtest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3aab3c931333>\u001b[0m in \u001b[0;36meval_in_batches\u001b[0;34m(data, sess)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             predictions[begin:end,:] = sess.run(eval_prediction,\n\u001b[0;32m--> 117\u001b[0;31m                                                 feed_dict={eval_data : data[begin:end, ...]})\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             batch_predictions = sess.run(eval_prediction,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a local session to run the training\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # run all the initializers to prepare the trainable parameters\n",
    "    tf.global_variables_initializer().run()\n",
    "    # Loop through training steps\n",
    "    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\n",
    "        # compute the offset of the current minibatch in the data\n",
    "        offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "        batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "        batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "        # This dictionary maps the batch data (as a numpy array) to the node \n",
    "        # in the graph it should be fed to\n",
    "        feed_dict = {train_data_node: batch_data,\n",
    "                     train_labels_node : batch_labels}\n",
    "        # Run the optimizer to update weights\n",
    "        sess.run(optimizer, feed_dict=feed_dict)\n",
    "        # print some extra information once we reach the evaluation frequency\n",
    "        if step % EVAL_FREQUENCY == 0:\n",
    "            # fetch some extra nodes' data\n",
    "            l, lr, predictions = sess.run([loss, learning_rate,\n",
    "                                           train_prediction],\n",
    "                                         feed_dict=feed_dict)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            print(\"Step %d (epoch %.2f), %.1f ms\" % (step, float(step) * BATCH_SIZE / train_size,\n",
    "                                                    1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "            print(\"Minibatch loss: %.3f, learning rate: %.6f\" % (l, lr))\n",
    "            print(\"Minibatch error: %.1f%%\" %error_rate(predictions, batch_labels))\n",
    "            print(\"Validation error: %.1f%%\" % error_rate(eval_in_batches(validation_data,\n",
    "                                                                         sess),\n",
    "                                                         validation_labels))\n",
    "            sys.stdout.flush()\n",
    "        #Finally print the result\n",
    "        test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "        print('Test error: %.1f%%' %test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
